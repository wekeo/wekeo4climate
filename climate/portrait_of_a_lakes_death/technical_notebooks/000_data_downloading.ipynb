{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7718fbc6",
   "metadata": {},
   "source": [
    "# Data downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fa0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hda\n",
    "from pathlib import Path\n",
    "from hda import Client, Configuration\n",
    "import os\n",
    "\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "\n",
    "from shapely import wkt\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "from pyproj import Proj\n",
    "from pyproj import Transformer\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "import shutil\n",
    "import pickle\n",
    "import zarr\n",
    "from glob import glob\n",
    "\n",
    "User = ''\n",
    "Password = ''\n",
    "Token = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c4d7c",
   "metadata": {},
   "source": [
    "## Search of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85df3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2a1e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 products found\n"
     ]
    }
   ],
   "source": [
    "api = SentinelAPI(User, Password,'https://apihub.copernicus.eu/apihub')\n",
    "first_date = date(2017, 1, 1)\n",
    "last_date = date(2017, 12, 31)\n",
    "\n",
    "footprint = \"POLYGON((-70.9649357878204 -33.81244707234685,-70.96591676385808 -33.89260670554516,-70.84251675089554 -33.89488656955273,-70.84506715448308 -33.81375110356652,-70.9649357878204 -33.81244707234685))\"\n",
    "\n",
    "products = api.query(footprint,\n",
    "                     date=(first_date, last_date),\n",
    "                         platformname='Sentinel-2',\n",
    "                     processinglevel='Level-1C')#,\n",
    "                     #cloudcoverpercentage=(0, 100))\n",
    "\n",
    "print(f'{len(products)} products found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce6a09",
   "metadata": {},
   "source": [
    "## Extract area of interest in original CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89857b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_geometry = [wkt.loads(footprint)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b88cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Configuration(user=User, password=Password)\n",
    "c = Client(config=config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a4e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "def area2ts(p):\n",
    "    n = p['filename'].split('.')[0]\n",
    "    datstrip = p['datastripidentifier'].split('_')[8][1:]\n",
    "    granuleid = p['granuleidentifier'].split('_')\n",
    "\n",
    "\n",
    "\n",
    "    identifier = p['identifier']\n",
    "    request = { \"datasetId\": \"EO:ESA:DAT:SENTINEL-2:MSI\",\n",
    "               \"stringInputValues\": [{\"name\": \"productIdentifier\", \"value\": identifier}]}\n",
    "\n",
    "    matches = c.search(request)\n",
    "    title = p['title']\n",
    "    matches.download()\n",
    "\n",
    "    filepath = title + '.zip'\n",
    "    with zipfile.ZipFile(filepath,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"./data\")\n",
    "    os.remove(filepath)\n",
    "\n",
    "\n",
    "    source_crs = \"EPSG:4326\"\n",
    "    \n",
    "    fullband = []\n",
    "\n",
    "    granule_folder = glob(\"./data/{}.SAFE/GRANULE/*/\".format(n), recursive = True)[0]\n",
    "    \n",
    "    for band in ['B01','B02','B03','B04','B05','B06','B07','B08','B09','B10','B11','B12','B8A']:\n",
    "        with rio.open('{}/IMG_DATA/{}_{}_{}.jp2'.format(granule_folder, n.split('_')[5], n.split('_')[2], band)) as img:\n",
    "            #print(img.meta)\n",
    "            # Error when loading the jp2 in mac or windows. I can't take the crs from the image. \n",
    "            target_crs = 'EPSG:32719'#img.crs.to_string()\n",
    "            x, y = initial_geometry[0].exterior.coords.xy\n",
    "\n",
    "            aoi = list(zip(x, y))\n",
    "            transformer = Transformer.from_crs(source_crs, target_crs)\n",
    "\n",
    "            new_coords = []\n",
    "            for co in aoi:\n",
    "                t = transformer.transform(co[1],co[0])\n",
    "                new_coords.append(t)\n",
    "\n",
    "            aoi = [Polygon(new_coords)]\n",
    "\n",
    "            clipped, transform = mask(img, aoi, crop=True)\n",
    "            metadata = img.meta.copy()\n",
    "\n",
    "            metadata.update({\"transform\": transform,\n",
    "                         \"height\": clipped.shape[1],\n",
    "                         \"width\": clipped.shape[2]#,\n",
    "                            #'driver': 'GTiff'\n",
    "                            })\n",
    "\n",
    "            with rio.open('./temp/{}_{}.tif'.format(n, band), 'w', **metadata) as dst:\n",
    "                dst.write(clipped)\n",
    "\n",
    "\n",
    "            with rio.open('./temp/{}_{}.tif'.format(n,band)) as r:\n",
    "                fullband.append(r.read())\n",
    "\n",
    "            os.remove('./temp/{}_{}.tif'.format(n,band))\n",
    "            os.remove('./temp/{}_{}.tif.aux.xml'.format(n,band)) \n",
    "\n",
    "    \n",
    "    fullband_resized = []\n",
    "    max_shape = tuple(np.max([np.shape(np.squeeze(band)) for band in fullband],axis=0))\n",
    "    \n",
    "    \n",
    "    for img in fullband:\n",
    "        if img.shape != max_shape:\n",
    "            image_resized = resize(np.squeeze(img), max_shape, anti_aliasing=False, preserve_range=True)\n",
    "            fullband_resized.append(image_resized)\n",
    "    \n",
    "    shutil.rmtree('./data/{}.SAFE'.format(n))\n",
    "    return np.array(fullband_resized, dtype=np.int16)\n",
    "\n",
    "def load_and_append_zarr(array, filename='output.zarr'):\n",
    "    if os.path.isdir(filename):\n",
    "        z = zarr.open(filename, mode='a')\n",
    "        z.append(array[np.newaxis])\n",
    "        zarr.save(filename, z)\n",
    "    else:\n",
    "        z.save(filename, array[np.newaxis])\n",
    "                      \n",
    "def load_and_expand_zarr(array, key, filename='output.zarr', debug=False):\n",
    "    if os.path.isdir(filename):\n",
    "        z = zarr.open(filename) #, mode='a')\n",
    "        z[key] = array\n",
    "        #zarr.save(filename, z)\n",
    "    else:\n",
    "        zarr.save(filename, **{key: array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce88345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TOA 2 LAC\n",
    "# import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from SIAC import SIAC_S2 #conda install lightgbm #https://github.com/multiply-org/atmospheric_correction\n",
    "# global_dem = '/vsicurl/https://gws-access.jasmin.ac.uk/public/nceo_ard/DEM_V3/global_dem.vrt'\n",
    "# cams_dir = '/vsicurl/https://gws-access.jasmin.ac.uk/public/nceo_ard/cams/'\n",
    "# SIAC_S2('S2B_MSIL1C_20181225T143749_N0207_R096_T19HCC_20181225T175914.SAFE', global_dem = global_dem, cams_dir=cams_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4b0eb",
   "metadata": {},
   "source": [
    "## Download of selected products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "797e1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing parallel loading of ZARR\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "def paral(func, lista, N, threads=True, processes=False):\n",
    "    if processes:\n",
    "        with ProcessPoolExecutor(max_workers=N) as executor:\n",
    "            results = executor.map(func, lista)\n",
    "        return list(results)\n",
    "    elif threads:\n",
    "        with ThreadPoolExecutor(max_workers=N) as executor:\n",
    "            results = executor.map(func, lista)\n",
    "        return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288db9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470e2932-6334-4b3d-a272-be23c63a2d1b already downloaded and processed\n",
      "92d7472f-8a5b-4196-a1f5-1dd36bbdd6e1 already downloaded and processed\n",
      "e543432e-946f-4ada-83ed-eb59baf18149 already downloaded and processed\n",
      "15a5e8db-fac1-47e4-81df-9a09ab02b408 already downloaded and processed\n"
     ]
    }
   ],
   "source": [
    "outputZarr = './data/2017.zarr'\n",
    "failedProducts = []\n",
    "for p in products:\n",
    "    try:\n",
    "        if os.path.isdir(outputZarr):\n",
    "            if p not in list(zarr.load(outputZarr)):\n",
    "                print('{} downloading new dataset'.format(p))\n",
    "                image = area2ts(products[p])\n",
    "                load_and_expand_zarr(image, p, filename=outputZarr)\n",
    "            else:\n",
    "                print('{} already downloaded and processed'.format(p))\n",
    "        else:\n",
    "            print('{} downloading new initial dataset'.format(p))\n",
    "            image = area2ts(products[p])\n",
    "            load_and_expand_zarr(image, p, filename=outputZarr)\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        if  os.path.isfile('{}.zip'.format(products[p]['title'])):\n",
    "            os.remove('{}.zip'.format(products[p]['title']))\n",
    "            \n",
    "        if  os.path.isdir('data/{}.SAFE'.format(products[p]['title'])):\n",
    "            shutil.rmtree('data/{}.SAFE'.format(products[p]['title']))\n",
    "            \n",
    "        failedProducts.append(p)\n",
    "        print('{} error. Ignoring dataset'.format(p))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbf91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## output of failed\n",
    "# with open('{}_failed.txt'.format(outputZarr.split('.')[0]), 'w') as fp:\n",
    "#     for item in np.unique(failedProducts):\n",
    "#         # write each item on a new line\n",
    "#         fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a890cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## do dataframe with the information. Basically matches to dataframe\n",
    "# entries = list(zarr.load(outputZarr))\n",
    "# df = api.to_dataframe(products)\n",
    "# df = df.loc[entries]\n",
    "# df.to_pickle('{}_df.pickle'.format(outputZarr.split('.')[0]))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e45c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"zip -r {}.zip {} \".format(outputZarr.split('.')[0], outputZarr)) #>/dev/null 2>&1\n",
    "# #os.system(\"unzip {}.zip\".format(outputZarr.split('.')[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial_3.8",
   "language": "python",
   "name": "geospatial_3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
