{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MRpqX7BjDsem"
      },
      "source": [
        "# xpopy\n",
        "This is an unofficial implementation for the paper below. The acceleration is mainly owing to the **ufuncs** in [PyGEOS](https://github.com/pygeos/pygeos) and [NumPy](https://github.com/numpy/numpy), which tries to avoid iteration to provide a better performance (~**10** times the speed over [the official one](https://github.com/Kang-Sun-CfA/Oversampling_matlab/blob/master/popy.py) under a two-core benchmark). In addition, the geometry operation seems to be more intuitive and easier to understand in the code snippets.  \n",
        "\n",
        "> Sun, K., Zhu, L., Cady-Pereira, K., Chan Miller, C., Chance, K., Clarisse, L., Coheur, P.-F., González Abad, G., Huang, G., Liu, X., Van Damme, M., Yang, K., and Zondlo, M.: A physics-based approach to oversample multi-satellite, multispecies observations to a common grid, Atmos. Meas. Tech., 11, 6679–6701, https://doi.org/10.5194/amt-11-6679-2018, 2018.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4cfdDr-wD6QT"
      },
      "source": [
        "## Data preparation\n",
        "Currently only tested on TROPOMI no2 data, so we pull the tropomi NO2 products from AWS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2-8wGj8Drmt",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87PCul6nEKAg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!aws s3 sync s3://meeo-s5p/OFFL/L2__NO2___/2022/07/24/ TROPOMI --no-sign-request\n",
        "!cp TROPOMI/S5P_OFFL_L2__NO2____20220724T0356*.nc ./"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ8Nn29pEPxg"
      },
      "source": [
        "## Original popy implementation\n",
        "forked from https://github.com/Kang-Sun-CfA/Oversampling_matlab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNrVItDrETQB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/HeQinWill/xpopy\n",
        "!cp xpopy/popy.py ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG-wngvhEkV8",
        "outputId": "315d07ce-6b1d-49a2-f1eb-5a1622e11385",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import popy\n",
        "\n",
        "l2_obj = popy.popy(\n",
        "        instrum='TROPOMI',\n",
        "        product='NO2',\n",
        "        grid_size=0.05,\n",
        "        west=110,\n",
        "        east=136,\n",
        "        south=10,\n",
        "        north=50,\n",
        "        start_year=2022,\n",
        "        start_month=7,\n",
        "        start_day=24,\n",
        "        start_hour=0,\n",
        "        start_minute=0,\n",
        "        start_second=0,\n",
        "        end_year=2022,\n",
        "        end_month=7,\n",
        "        end_day=24,\n",
        "        end_hour=5,\n",
        "        end_minute=22,\n",
        "        end_second=59,\n",
        "        verbose=True,\n",
        ")\n",
        "\n",
        "l2_obj.min_qa_value = 0.75\n",
        "l2_obj.F_subset_S5PNO2(path ='/content',\n",
        "                s5p_product='OFFL',\n",
        "                data_fields=[],\n",
        "                data_fields_l2g=[])\n",
        "\n",
        "print(l2_obj.pixel_shape)\n",
        "l2_obj.l2_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuGVluh2E3Mu",
        "outputId": "8e2b091b-8c92-42d3-99cc-3872661d3b53",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "l3 = l2_obj.F_parallel_regrid(ncores=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RtSSHN4YE-ok"
      },
      "source": [
        "## Compact xpopy implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xBo3hxrFF9O",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install pygeos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a2SDEQKFBkb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pygeos\n",
        "from pygeos import polygons, linestrings, points\n",
        "from pygeos.measurement import area, distance, length\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-u-M4EmE9_a",
        "outputId": "be5487e7-d62b-49cf-9eae-1b3b143cc507",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# copy values from popy l2_obj\n",
        "# TODO: read the original data directly\n",
        "l2g_data = l2_obj.l2g_data\n",
        "\n",
        "nl2 = len(l2g_data['latc'])\n",
        "latc = l2g_data['latc'].data\n",
        "lonc = l2g_data['lonc'].data\n",
        "latr = l2g_data['latr'].data\n",
        "lonr = l2g_data['lonr'].data\n",
        "\n",
        "west = l2_obj.west\n",
        "east = l2_obj.east\n",
        "south = l2_obj.south \n",
        "north = l2_obj.north\n",
        "grid_size = l2_obj.grid_size\n",
        "\n",
        "ce_l3 = np.tile((l2_obj.xmesh, l2_obj.ymesh),1).reshape(2,-1).T\n",
        "\n",
        "# construct l2 swath geometry polygons\n",
        "l2 = polygons(np.stack((lonr,latr), axis=-1))\n",
        "\n",
        "# calculate the area of each polygon\n",
        "area_weight = area(l2)\n",
        "\n",
        "# construct l2 swath corner points\n",
        "lb = points(np.stack((lonr[:,0],latr[:,0]), axis=-1))\n",
        "lt = points(np.stack((lonr[:,1],latr[:,1]), axis=-1))\n",
        "rt = points(np.stack((lonr[:,2],latr[:,2]), axis=-1))\n",
        "rb = points(np.stack((lonr[:,3],latr[:,3]), axis=-1))\n",
        "\n",
        "# calculate the length and set the fwhm\n",
        "# 0.25 = 0.5 (Half) × 0.5 (the average length of two sides)\n",
        "fwhmx = (distance(lt, rt)+distance(lb, rb))*0.25\n",
        "fwhmy = (distance(lt, lb)+distance(rt, rb))*0.25\n",
        "\n",
        "# equation 6&7\n",
        "k1 = 4\n",
        "k2 = 2\n",
        "k3 = 1\n",
        "wx = fwhmx/(np.log(2)**(1/k1/k3))\n",
        "wy = fwhmy/(np.log(2)**(1/k2/k3))\n",
        "\n",
        "# construt the transformed coordinates using fwhm\n",
        "dst = [[-fwhmx,-fwhmy],[-fwhmx,fwhmy],[fwhmx,fwhmy],[fwhmx,-fwhmy]]\n",
        "dst = np.array(dst, dtype='float32')  # (4, 2, nl2)\n",
        "\n",
        "# calculate the difference between the 4 corners and the center point\n",
        "# set the center point to the coordinate origin\n",
        "lond = lonr - lonc.reshape(-1,1)\n",
        "latd = latr - latc.reshape(-1,1)\n",
        "src = np.stack((lond, latd), axis=-1)\n",
        "src = np.array(src, dtype='float32')  # (nl2, 4, 2)\n",
        "\n",
        "# derive the perspective transform parameters\n",
        "tform = [cv2.getPerspectiveTransform(src[i], dst[:,:,i]) for i in range(nl2)]\n",
        "tform = np.array(tform)\n",
        "\n",
        "# construct R-tree of l3 center points\n",
        "l3_tree = pygeos.STRtree(points(ce_l3), leafsize=128)\n",
        "\n",
        "# set l2 buffer\n",
        "# 1. no buffer\n",
        "# l2_buffer = l2\n",
        "# 2. simple buffer (uniform with the half of max{fwhmx,fwhmy} of each polygon)\n",
        "margin = fwhmx.copy()\n",
        "margin[fwhmy>fwhmx] = fwhmy[fwhmy>fwhmx]\n",
        "l2_buffer = pygeos.buffer(l2, margin/2)\n",
        "# 3. polygon with a margin (consistent with source code)\n",
        "# TODO\n",
        "\"\"\"\n",
        "# Maybe judging whether the l2 polygon is overlapped with the l3 grid is enough\n",
        "l3_geo = polygons(np.stack((lb_l3,lt_l3,rt_l3,rb_l3), axis=1))\n",
        "l3_tree = pygeos.STRtree(l3_geo, leafsize=128)\n",
        "t = l3_tree.query_bulk(l2, predicate='overlaps')\n",
        "\"\"\"\n",
        "\n",
        "# find all situation where l2 buffer polygons contains the l3 center points\n",
        "# t[0]: the 1st dimesion is l2 object index\n",
        "# t[1]: the 2nd dimesion is l3 object index\n",
        "t = l3_tree.query_bulk(l2_buffer, predicate='contains')\n",
        "\n",
        "# calculate the difference between the l3 center and the corresponding l2 center\n",
        "xym1 = ce_l3[t[1]] - np.stack((lonc[t[0]], latc[t[0]]),axis=-1)\n",
        "\n",
        "# apply the perspective transform parametes\n",
        "# only the first 6 parameters (2 lines) need to be used\n",
        "a = tform[t[0], :2]  # (T, 2, 3)\n",
        "b = np.column_stack((xym1, np.ones(len(xym1)) ))[:,:,np.newaxis]  # (T, 2+1, 1)\n",
        "xym2 = np.matmul(a,b).squeeze()  # (T, 2, 1) -> (T, 2)\n",
        "\n",
        "# equation 5\n",
        "x_term = -np.abs(xym2[:,0]/wx[t[0]])**k1\n",
        "y_term = -np.abs(xym2[:,1]/wy[t[0]])**k2\n",
        "\n",
        "# record with a table for subsequent processing\n",
        "df = pd.DataFrame()\n",
        "df['lon'] = ce_l3[t[1], 0]\n",
        "df['lat'] = ce_l3[t[1], 1]\n",
        "df['sg'] = np.exp(x_term+y_term)\n",
        "df['area_weight'] = area_weight[t[0]]\n",
        "df['uncertainty_weight'] = l2g_data['column_uncertainty'].data[t[0]]\n",
        "df['tmp_wt'] = df['sg']/df['area_weight']/df['uncertainty_weight']\n",
        "for ivar in ['column_amount', 'albedo', 'surface_altitude']:\n",
        "    df[f'sum_aboves_{ivar}'] = df['tmp_wt'] * l2g_data[ivar].data[t[0]]\n",
        "\n",
        "# sum the values of each grid at the same location\n",
        "# then merge it with an empty table of full grids\n",
        "df_ = pd.DataFrame(ce_l3, columns=['lon', 'lat'])\n",
        "df_.set_index(['lat', 'lon'], inplace=True)\n",
        "df_ = df_.merge(df.groupby(['lat', 'lon']).sum(),\n",
        "                how='left', left_index=True, right_index=True)\n",
        "\n",
        "# rename the column name and set the quality flag\n",
        "df_ = df_.rename(columns={'sg':'num_samples', 'tmp_wt':'total_sample_weight'})\n",
        "df_['quality_flag'] = 2\n",
        "df_.loc[df_.num_samples >= 0.1, 'quality_flag'] = 1\n",
        "df_.loc[(df_.num_samples > 1.e-6)&(df_.num_samples < 0.1), 'quality_flag'] = 0\n",
        "\n",
        "# convert the table to an xarray dataset\n",
        "ds = df_.to_xarray()\n",
        "ds['lat'].attrs = {'units': 'degree_north'}\n",
        "ds['lon'].attrs = {'units': 'degree_east'}\n",
        "for ivar in ['column_amount', 'albedo', 'surface_altitude']:\n",
        "    ds[ivar] = ds[f'sum_aboves_{ivar}']/ds['total_sample_weight']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hMdzN2b7JvmW"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1OmLMulJaWv",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ds['column_amount_from_popy'] = ds['column_amount'].copy()\n",
        "ds['column_amount_from_popy'][:] = l3['column_amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "n_DCB-5-KhiI",
        "outputId": "c5d94116-bfd8-4d66-a354-8edc1e27b968",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(18,3))\n",
        "ds['column_amount_from_popy'].plot(ax=ax1, vmin=0, vmax=0.0003)\n",
        "ds['column_amount'].plot(ax=ax2, vmin=0, vmax=0.0003)\n",
        "(ds['column_amount_from_popy'] - ds['column_amount']).plot(ax=ax3, vmin=-5e-5)"
      ]
    }
  ],
  "metadata": {
    "title": "Xpopy",
    "description": "This is an unofficial implementation for the following paper: https://doi.org/10.5194/amt-11-6679-2018. The acceleration is mainly owing to the ufuncs in PyGEOS and NumPy, which tries to avoid iteration to provide a better performance (~10 times the speed over the official one under a two-core test)..",
    "author": "Qin He",
    "image": "./img/thumb.png",
    "services": {
          "wekeo": {
               "git": {
                    "link": "https://github.com/wekeo/wekeo4climate/blob/main/climate/xpopy/xpopy_demo.ipynb",
                    "service_contact": "support@wekeo.eu",
                    "service_provider": "WEKEO"},
               "jupyter": {
                    "link": "https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/hub/user-redirect/lab/tree/public/wekeo4climate/climate/xpopy/xpopy_demo.ipynb",
                    "service_contact": "support@wekeo.eu",
                    "service_provider": "WEKEO"}
          }
      },
    "tags": {
     "domain": "Atmosphere",
     "subtheme": "Air Quality",
     "sensor": "TROPOMI",
     "tags": [
       "Carbon monoxide"
     ],
     "platform": "Sentinel-5P",
     "service": "ESA"
    },
    "colab": {
      "collapsed_sections": [],
      "name": "xpopy_demo",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
